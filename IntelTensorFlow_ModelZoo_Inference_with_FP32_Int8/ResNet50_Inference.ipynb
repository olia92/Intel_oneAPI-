{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Getting Started with [Intel Model Zoo](https://github.com/IntelAI/models)\n",
    "\n",
    "This code sample will serve as a sample use case to perform TensorFlow ResNet50 inference on a synthetic data implementing a FP32 and Int8 pre-trained model. The pre-trained model published as part of Intel Model Zoo will be used in this sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select precision and download model\n",
    "Select the precision that you would like to run resnet50 model with. `fp32` or `int8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#olia \n",
    "import getpass\n",
    "import os\n",
    "\n",
    "password = getpass.getpass()\n",
    "command = \"sudo -S apt-get update\" #can be any command but don't forget -S as it enables input from stdin\n",
    "os.system('echo %s | %s' % (password, command))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = \"int8\"  # or \"fp32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "initial_cwd = os.getcwd()\n",
    "model_bucket = 'https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/'\n",
    "model_file = 'resnet50_' + precision + '_pretrained_model.pb'\n",
    "model_download_path = os.path.join(model_bucket, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download Intel's pretrained resnet50 model\n",
    "if not os.path.exists(os.path.join(os.getcwd(), model_file)):\n",
    "    ! wget $model_download_path\n",
    "model_local_path = os.path.join(os.getcwd(), model_file)\n",
    "if not os.path.exists(model_local_path):\n",
    "    raise Exception(\"Failed to download pretrained Model file {}\", model_download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a synthetic dataset of size 244x244.\n",
    "It is important to set optimial batch_size, MKL run-time settings, TensorFlow's inter-intra number of threads to enable compute and data layer optimizations. We have identified optimial settings for popular topologies including ResNet50 to maximize CPU utlization. For more details on Run-time settings refer to blogs [maximize CPU performance](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference), [Intel Model Zoo tutorials](https://github.com/IntelAI/models/tree/master/docs). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/modelzoo/2.5.0\n"
     ]
    }
   ],
   "source": [
    "%cd /opt/intel/oneapi/modelzoo/latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch and Online Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Running int8 inference with blocked format. Native format will be supported in future TensorFlow releases. Please don't define TF_ENABLE_MKL_NATIVE_FORMAT in CLI unless native format is enabled for your installed TensorFlow version.\n",
      "Running with parameters:\n",
      "    USE_CASE: image_recognition\n",
      "    FRAMEWORK: tensorflow\n",
      "    WORKSPACE: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/common/tensorflow\n",
      "    DATASET_LOCATION: \n",
      "    CHECKPOINT_DIRECTORY: \n",
      "    BACKBONE_MODEL_DIRECTORY: \n",
      "    IN_GRAPH: /home/olia/IntelTensorFlow_ModelZoo_Inference_with_FP32_Int8/resnet50_int8_pretrained_model.pb\n",
      "    MOUNT_INTELAI_MODELS_COMMON_SOURCE_DIR: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/../models/common/tensorflow\n",
      "    Mounted volumes:\n",
      "        /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks mounted on: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks\n",
      "        None mounted on: None\n",
      "        /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/../models/image_recognition/tensorflow/resnet50 mounted on: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/../models/image_recognition/tensorflow/resnet50\n",
      "        None mounted on: \n",
      "        None mounted on: \n",
      "        None mounted on: \n",
      "    SOCKET_ID: 0\n",
      "    MODEL_NAME: resnet50\n",
      "    MODE: inference\n",
      "    PRECISION: int8\n",
      "    BATCH_SIZE: 128\n",
      "    NUM_CORES: -1\n",
      "    BENCHMARK_ONLY: True\n",
      "    ACCURACY_ONLY: False\n",
      "    OUTPUT_RESULTS: False\n",
      "    DISABLE_TCMALLOC: False\n",
      "    TCMALLOC_LARGE_ALLOC_REPORT_THRESHOLD: 2147483648\n",
      "    NOINSTALL: True\n",
      "    OUTPUT_DIR: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/common/tensorflow/logs\n",
      "    MPI_NUM_PROCESSES: None\n",
      "    MPI_NUM_PEOCESSES_PER_SOCKET: 1\n",
      "    MPI_HOSTNAMES: None\n",
      "    NUMA_CORES_PER_INSTANCE: None\n",
      "    PYTHON_EXE: /usr/bin/python3\n",
      "    PYTHONPATH: /opt/intel/oneapi/advisor/2022.0.0/pythonapi\n",
      "    DRY_RUN: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/common/tensorflow/logs’: Permission denied\n",
      "tee: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/common/tensorflow/logs/benchmark_resnet50_inference_int8_20211227_114850.log: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/../models/image_recognition/tensorflow/resnet50/inference/eval_image_classifier_inference.py:156: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /home/olia/.local/lib/python3.8/site-packages/tensorflow/python/tools/strip_unused_lib.py:87: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "WARNING:tensorflow:From /home/olia/.local/lib/python3.8/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py:116: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n",
      "2021-12-27 11:48:53.140645: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-27 11:48:53.185007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.192789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.193437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.808596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.809162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.809601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.809995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1383 MB memory:  -> device: 0, name: GeForce 920M, pci bus id: 0000:04:00.0, compute capability: 3.5\n",
      "2021-12-27 11:48:53.812506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.813138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.813656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.814279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.814832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-27 11:48:53.815671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1383 MB memory:  -> device: 0, name: GeForce 920M, pci bus id: 0000:04:00.0, compute capability: 3.5\n",
      "2021-12-27 11:48:54.714082: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n",
      "2021-12-27 11:48:55.564844: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 916.38MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "Run inference\n",
      "Inference with dummy data.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/olia/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/olia/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1359, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/home/olia/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1451, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.\n",
      "  (0) Internal: Missing 0-th output from {{node v0/resnet_v10/conv2/conv2d/Conv2D_eightbit_requantize}}\n",
      "  (1) Internal: Missing 0-th output from {{node v0/resnet_v10/conv2/conv2d/Conv2D_eightbit_requantize}}\n",
      "\t [[v0/resnet_v115/Relu/_5]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/../models/image_recognition/tensorflow/resnet50/inference/eval_image_classifier_inference.py\", line 271, in <module>\n",
      "    evaluate_opt_graph.run()\n",
      "  File \"/opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/../models/image_recognition/tensorflow/resnet50/inference/eval_image_classifier_inference.py\", line 197, in run\n",
      "    predictions = infer_sess.run(output_tensor, feed_dict={input_tensor: image_np})\n",
      "  File \"/home/olia/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/home/olia/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/home/olia/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1368, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/home/olia/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1394, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.\n",
      "  (0) Internal: Missing 0-th output from node v0/resnet_v10/conv2/conv2d/Conv2D_eightbit_requantize (defined at opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/../models/image_recognition/tensorflow/resnet50/inference/eval_image_classifier_inference.py:162) \n",
      "  (1) Internal: Missing 0-th output from node v0/resnet_v10/conv2/conv2d/Conv2D_eightbit_requantize (defined at opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/../models/image_recognition/tensorflow/resnet50/inference/eval_image_classifier_inference.py:162) \n",
      "\t [[v0/resnet_v115/Relu/_5]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "Warning: Unable to find the TCMalloc library file (libtcmalloc.so) in /usr/lib or /usr/lib64, so the LD_PRELOAD environment variable will not be set.\n",
      "Ran inference with batch size 128\n",
      "Log file location: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/common/tensorflow/logs/benchmark_resnet50_inference_int8_20211227_114850.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tee: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/common/tensorflow/logs/benchmark_resnet50_inference_int8_20211227_114850.log: No such file or directory\n",
      "tee: /opt/intel/oneapi/modelzoo/2.5.0/models/benchmarks/common/tensorflow/logs/benchmark_resnet50_inference_int8_20211227_114850.log: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Run inference using --batch-size=128 for throughput, or --batch-size=1 for latency\n",
    "%run models/benchmarks/launch_benchmark.py \\\n",
    "    --in-graph $model_local_path \\\n",
    "    --model-name resnet50 \\\n",
    "    --framework tensorflow \\\n",
    "    --precision $precision \\\n",
    "    --mode inference \\\n",
    "    --batch-size=128 \\\n",
    "    --socket-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output(both stdout and stderr) is displayed on the command line console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CODE_SAMPLE_COMPLETED_SUCCESFULLY]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(initial_cwd)\n",
    "print('[CODE_SAMPLE_COMPLETED_SUCCESFULLY]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
