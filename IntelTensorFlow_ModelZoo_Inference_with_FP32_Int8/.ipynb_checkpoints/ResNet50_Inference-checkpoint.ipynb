{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Getting Started with [Intel Model Zoo](https://github.com/IntelAI/models)\n",
    "\n",
    "This code sample will serve as a sample use case to perform TensorFlow ResNet50 inference on a synthetic data implementing a FP32 and Int8 pre-trained model. The pre-trained model published as part of Intel Model Zoo will be used in this sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select precision and download model\n",
    "Select the precision that you would like to run resnet50 model with. `fp32` or `int8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = \"fp32\"  # or \"int8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "initial_cwd = os.getcwd()\n",
    "model_bucket = 'https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/'\n",
    "model_file = 'resnet50_' + precision + '_pretrained_model.pb'\n",
    "model_download_path = os.path.join(model_bucket, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-26 20:49:09--  https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/resnet50_fp32_pretrained_model.pb\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.206.176, 216.58.214.144, 142.250.187.112, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.206.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 102559229 (98M) [application/octet-stream]\n",
      "Saving to: ‘resnet50_fp32_pretrained_model.pb’\n",
      "\n",
      "resnet50_fp32_pretr 100%[===================>]  97,81M  2,96MB/s    in 35s     \n",
      "\n",
      "2021-12-26 20:49:45 (2,76 MB/s) - ‘resnet50_fp32_pretrained_model.pb’ saved [102559229/102559229]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download Intel's pretrained resnet50 model\n",
    "if not os.path.exists(os.path.join(os.getcwd(), model_file)):\n",
    "    ! wget $model_download_path\n",
    "model_local_path = os.path.join(os.getcwd(), model_file)\n",
    "if not os.path.exists(model_local_path):\n",
    "    raise Exception(\"Failed to download pretrained Model file {}\", model_download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a synthetic dataset of size 244x244.\n",
    "It is important to set optimial batch_size, MKL run-time settings, TensorFlow's inter-intra number of threads to enable compute and data layer optimizations. We have identified optimial settings for popular topologies including ResNet50 to maximize CPU utlization. For more details on Run-time settings refer to blogs [maximize CPU performance](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference), [Intel Model Zoo tutorials](https://github.com/IntelAI/models/tree/master/docs). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /opt/intel/oneapi/modelzoo/latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch and Online Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference using --batch-size=128 for throughput, or --batch-size=1 for latency\n",
    "%run models/benchmarks/launch_benchmark.py \\\n",
    "    --in-graph $model_local_path \\\n",
    "    --model-name resnet50 \\\n",
    "    --framework tensorflow \\\n",
    "    --precision $precision \\\n",
    "    --mode inference \\\n",
    "    --batch-size=128 \\\n",
    "    --socket-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output(both stdout and stderr) is displayed on the command line console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(initial_cwd)\n",
    "print('[CODE_SAMPLE_COMPLETED_SUCCESFULLY]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
